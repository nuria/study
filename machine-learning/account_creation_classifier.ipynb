{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import uuid\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "! pip install seaborn\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from app.io import redshift\n",
    "from app.io.s3 import write_df\n",
    "from app.util.env import IS_PRODUCTION\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# says it should not be used for categorical values but not clear why\\n\",\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = '%(asctime)s %(message)s'\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "root_path = os.environ.get('PYTHONPATH')\n",
    "\n",
    "if IS_PRODUCTION:\n",
    "    root_path = \"/opt/compute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for training\n",
    "\n",
    "# \n",
    "# this dataset is much better from november on but includes less fraudulent accounts \n",
    "# so we will do more tries\n",
    "# we need to make sure this is balanced \n",
    "query = \"\"\"\n",
    "select has_anonymous_id, \n",
    "share_invite_link,\n",
    "country,\n",
    "len_user_name,\n",
    "email_domain,\n",
    "user_name,\n",
    "browser_tz,\n",
    "number_pageviews,\n",
    "utm_medium,\n",
    "is_fraud as is_suspended\n",
    "\n",
    "from nuriaruiz_dbt_dev_compute.account_creation_classifier_training_dataset \n",
    "where (is_fraud > 0 or (random_marker > 0.99 and received_at > '2022-01-01'))\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "df = redshift.read(query)\n",
    "\n",
    "logger.info(\"Finish Reading data from Redshift\")\n",
    "#print (df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how balanced is the variable we are trying to predict\n",
    "# aim for about 30%\n",
    "print (\"label value counts\")\n",
    "print (df['is_suspended'].value_counts())\n",
    "print (df['is_suspended'].value_counts().plot(kind='bar', title='Is_suspended Distribution'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the user name for fraudulent accounts looks like 'qwrbqw' and similar\n",
    "# adding here a feature that might provide this signal, we identify the \n",
    "# number of 4 consonant groups on a user name and add the number of them we find as a feature\n",
    "# example 'Chaiyuth Tangsurakit' has zero 4 consonant groups\n",
    "# and 'db sdb sdbsdb' has two\n",
    "# this only works for western names !!!!!\n",
    "# we use a large number for empty names\n",
    "\n",
    "consonant_groups = []\n",
    "\n",
    "for user_name in df['user_name']:\n",
    "    \n",
    "    if user_name is None:\n",
    "        consonant_groups.append(10)\n",
    "    else:\n",
    "        #print (user_name)\n",
    "        tally = []\n",
    "        user_name= user_name\n",
    "        for u in user_name.split():\n",
    "            finds = (re.findall(r'[^aeiouy]{4,}', u))\n",
    "            if len(finds)!= 0:\n",
    "                tally.append(finds)\n",
    "        consonant_groups.append(len(tally))\n",
    "        \n",
    "\n",
    "\n",
    "df['user_name_consonant_groups'] = consonant_groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in df['user_name_consonant_groups']:\n",
    "#    if c > 1:\n",
    "#        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Value counts\")\n",
    "print (df['country'].value_counts())\n",
    "print(df['email_domain'].value_counts())\n",
    "\n",
    "\n",
    "# label encoding for categorical features\n",
    "le = LabelEncoder()\n",
    "for col in ('country', 'browser_tz', 'utm_medium', 'email_domain', 'user_name'):\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "\n",
    "    \n",
    "#print (\"Max min country\")\n",
    "#print (max(df['country']))\n",
    "#print (min(df['country']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to drop the predicted variable\n",
    "target = df['is_suspended']\n",
    "features = df.drop('is_suspended', axis=1)\n",
    "\n",
    "print (features)\n",
    "# use 80% of data for training, random_state controls the shuffle of data before it is passed to training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, train_size=0.75,test_size=0.25)\n",
    "# scale all below 1 with  x_scaled = (x-x_min)/X_max-X_min\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# we want to scale training set and testing set separately\n",
    "# to avoid data leakage\n",
    "# https://machinelearningmastery.com/data-preparation-without-data-leakage/\n",
    "x_train_min_max = min_max_scaler.fit_transform(x_train)\n",
    "x_test_min_max = min_max_scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x_test_min_max[4:6])\n",
    "print (y_test[4:6])\n",
    "print(df[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix among two variables, remove variables highly correlated\n",
    "# more ways to identify relationships:\n",
    "# https://medium.com/geekculture/feature-selection-in-machine-learning-correlation-matrix-univariate-testing-rfecv-1186168fac12\n",
    "#plt.matshow(x_train.corr())\n",
    "#plt.show()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=bool),\n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a logistic regression model to the data\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_min_max, y_train)\n",
    "\n",
    "\n",
    "# this is a fraudulent record of testing set\n",
    "p = model.predict([[0, 0, 1, 0,  0.32979852, 1,0.27419355, 0, 1,  1 ]])\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the fraudulent transactions on the test data\n",
    "print (x_test_min_max)\n",
    "\n",
    "predictions = model.predict(x_test_min_max).round()\n",
    "#print(predictions)\n",
    "#print (y_test)\n",
    "\n",
    "# more metrics here: \n",
    "#https://medium.com/@oluwabukunmige/logistic-regression-in-scikit-learn-a-step-by-step-process-32f546241f32\n",
    "\n",
    "# Evaluate the model on the the data\n",
    "# returns mean of accuracy (average of wrong or right per sample)\n",
    "# careful, if there is data imbalance and you have few fraud samples \n",
    "# accuracy could be high but still you cannot predict\n",
    "print(\"Score training data:\")\n",
    "print(model.score(x_train_min_max, y_train))\n",
    "print(\"Score test data:\")\n",
    "print (model.score(x_test_min_max, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TP FP\n",
    "#  FN TN\n",
    "#confusion = confusion_matrix(x_test_min_max, predictions)\n",
    "#print(confusion)\n",
    "print(classification_report(y_test, predictions, target_names=['0', '1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
